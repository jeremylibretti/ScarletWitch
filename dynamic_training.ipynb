{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/dynamic_classifier/dynamic_data.csv'\n",
    "model_save_path = 'model/dynamic_classifier/dynamic_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_dataset = np.loadtxt(dataset, delimiter=\",\", dtype='float32', skiprows=1)[:,1:]\n",
    "X_dataset = np.genfromtxt(dataset, delimiter=\",\", dtype='float32')[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = math.ceil(len(X_dataset[0])/42)\n",
    "DIMENSION = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_lstm = False\n",
    "model = None\n",
    "\n",
    "if use_lstm:\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "        tf.keras.layers.Reshape((TIME_STEPS, DIMENSION), input_shape=(TIME_STEPS * DIMENSION, )), \n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.LSTM(16, input_shape=[TIME_STEPS, DIMENSION]),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "else:\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(24, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 2184)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                52440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                250       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 52,712\n",
      "Trainable params: 52,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: nan - accuracy: 0.5185 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00001: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5219 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00002: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5219 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00003: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5089 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00004: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5089 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00005: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5089 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00006: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5037 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00007: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5089 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00008: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5219 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00009: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: nan - accuracy: 0.5167 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00010: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5089 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00011: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5193 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00012: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5141 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00013: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5167 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00014: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5193 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00015: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5245 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00016: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5089 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00017: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5167 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00018: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.5115 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00019: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.5141 - val_loss: nan - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00020: saving model to model/dynamic_classifier\\dynamic_classifier.hdf5\n",
      "Epoch 00020: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x299090c80a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference test\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to model for Tensorflow-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path, include_optimizer=False)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_save_path = 'model/dynamic_classifier/dynamic_classifier.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform (quantize) model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)  # converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get I/O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
